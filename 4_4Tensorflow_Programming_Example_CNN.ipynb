{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBSljh+F7h71lY017ECLJg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zelal-Eizaldeen/deeplearning_course/blob/main/4_4Tensorflow_Programming_Example_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In this programming example, we will demonstrate how to do **image classification using a convolutional neural network implemented using Tensorflow.**"
      ],
      "metadata": {
        "id": "cvGZJh4AOSzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Google Colab notebook, we will do **image classification with a convolutional neural network**. We start with importing some of the TensorFlow modules here. We will train it for **32 epochs and use a batch size of 32**."
      ],
      "metadata": {
        "id": "i7TFNfg1Pbb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "import numpy as np\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "EPOCHS = 32\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "DG1HA1p3QJeb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We **load the dataset with keras datasets.cifar10**."
      ],
      "metadata": {
        "id": "RZ6w4xFjQMgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset.\n",
        "cifar_dataset = keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images,\n",
        "    test_labels) = cifar_dataset.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKHRmc7PQNVw",
        "outputId": "b0f6d896-ee05-4abe-bc16-5e7d8ee9b734"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before we want to **standardize this dataset** so we **compute the mean and standard deviation**, **so we can then standardize both the training images and the test images.**"
      ],
      "metadata": {
        "id": "Z-qwEPvGP8as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize dataset.\n",
        "mean = np.mean(train_images)\n",
        "stddev = np.std(train_images)\n",
        "train_images = (train_images - mean) / stddev\n",
        "test_images = (test_images - mean) / stddev\n",
        "print('mean: ', mean)\n",
        "print('stddev: ', stddev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx4pf0cMQULX",
        "outputId": "50d0d955-e251-4701-a268-50bda6003d83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean:  120.70756512369792\n",
            "stddev:  64.1500758911213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also want to **encode our training labels as one hot encoding**, and we use do that using the two categorical function. And we say that we want it with 10 different classes, **so 10 outputs later for our network**.  "
      ],
      "metadata": {
        "id": "BIUJVTfeQeSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change labels to one-hot.\n",
        "train_labels = to_categorical(train_labels,\n",
        "                              num_classes=10)\n",
        "test_labels = to_categorical(test_labels,\n",
        "                             num_classes=10)"
      ],
      "metadata": {
        "id": "i74TQhS2QjeN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the CNN"
      ],
      "metadata": {
        "id": "Cyk-qWDuRCoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now look at how **we can define our network**. So it's a **sequential** network as before where we stacked a number of layers on top of each other. It consists of **two convolutional layers** and **one fully connected layer**.  **We can see a one difference between this and the digit classification network is that we don't have a flattened layer at the very beginning of the network**."
      ],
      "metadata": {
        "id": "aPLHtN6bRGP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We needed to have the flattened layer because the **fully connected layer, which was the first layer assumed a 1D array as inputs**. **But the convolutional layer assumes that we have a 3D array, which is the image input**. So it's **two dimensions plus the number of colored channels that makes it three.**"
      ],
      "metadata": {
        "id": "yktwUOpGRfhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So if we look at this **convolutional layer**. The **first convolutional layer**,\n",
        "- we say that **we want 64 output channels.** We want **a kernel size of five by five and a stride of two by two**. We use **relu activation and we use padding equals same**.\n",
        "- With padding \"same\":  If we had **a stride of one by one, then the output dimension would be the same** as the input dimension.\n",
        "-  But given that we then have **a stride of two**, it means that the **output dimension will be exactly half of the input dimension**. So with an **input shape of 32 by 32 by three, the output will now be 16 by 16, and then by the number of channels,** **which is 64**.\n"
      ],
      "metadata": {
        "id": "05iUTJd8RtgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we use **he normal initialization for the weights**, and we set the **biases** to zero."
      ],
      "metadata": {
        "id": "DbGSk3gISqfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with two convolutional and one fully connected layer.\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (5, 5), strides=(2,2),\n",
        "                 activation='relu', padding='same',\n",
        "                 input_shape=(32, 32, 3),\n",
        "                 kernel_initializer='he_normal',\n",
        "                 bias_initializer='zeros'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R9aktNFSU38",
        "outputId": "d810a158-9f6a-443e-cea0-92fbdccb2aff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Second convolutional layer**, we also use **64 channels**. We have a smaller **kernel size, three by three**, *stride, two by two*. **Again, relu same, he normal and zeros.**"
      ],
      "metadata": {
        "id": "uX_bO0EtS4VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(64, (3, 3), strides=(2,2),\n",
        "                 activation='relu', padding='same',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 bias_initializer='zeros'))"
      ],
      "metadata": {
        "id": "tY4BTYVbUu2d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we go **from a convolutional layer to a fully connected layer**. And there we have a **mismatch in dimensions because we have a 3D structure from the convolutional layer and a assuming a 1D dimension for the fully connected layer, so there we need to insert this flattened layer**."
      ],
      "metadata": {
        "id": "NOisIoXLUtKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "wjt_75xhU-ko"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then this is **our output layer**, which has **10 neurons**. **Activation is soft max**. We use **glorot initialization of the weights and zeros for the bias**."
      ],
      "metadata": {
        "id": "igCMSCnuVGgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(10, activation='softmax',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                bias_initializer='zeros'))"
      ],
      "metadata": {
        "id": "uS1ut0JHVDbA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then as we use soft max, we want to use **the categorical cross entropy as a loss function**. And we use the **Adam optimizer**. We also want to print out the **accuracy**, and then we'll print out **the summary of the model**."
      ],
      "metadata": {
        "id": "TFBF-QPrVQdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics =['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "kjI6GipEVPj3",
        "outputId": "c6f58f55-85dd-4626-b754-69f46034b32d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m40,970\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,970</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,762\u001b[0m (323.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,762</span> (323.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,762\u001b[0m (323.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,762</span> (323.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then the training of the network. We call the **fit function with train images and train labels, validation_data is the test images and test labels**. And then we tell how many **epochs** the **batch** size and so on."
      ],
      "metadata": {
        "id": "X8jDq5gIVndg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_images, train_labels, validation_data =\n",
        "    (test_images, test_labels), epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE, verbose=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYLt_YhNV524",
        "outputId": "ed2aed44-bcf5-474a-cecf-af47ca2b45b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "1563/1563 - 50s - 32ms/step - accuracy: 0.5050 - loss: 1.4025 - val_accuracy: 0.5889 - val_loss: 1.1703\n",
            "Epoch 2/32\n",
            "1563/1563 - 45s - 29ms/step - accuracy: 0.6323 - loss: 1.0587 - val_accuracy: 0.6315 - val_loss: 1.0599\n",
            "Epoch 3/32\n",
            "1563/1563 - 48s - 30ms/step - accuracy: 0.6791 - loss: 0.9205 - val_accuracy: 0.6364 - val_loss: 1.0527\n",
            "Epoch 4/32\n",
            "1563/1563 - 77s - 49ms/step - accuracy: 0.7139 - loss: 0.8240 - val_accuracy: 0.6491 - val_loss: 1.0293\n",
            "Epoch 5/32\n",
            "1563/1563 - 84s - 54ms/step - accuracy: 0.7406 - loss: 0.7447 - val_accuracy: 0.6313 - val_loss: 1.1068\n",
            "Epoch 6/32\n",
            "1563/1563 - 44s - 28ms/step - accuracy: 0.7652 - loss: 0.6753 - val_accuracy: 0.6532 - val_loss: 1.0832\n",
            "Epoch 7/32\n",
            "1563/1563 - 81s - 52ms/step - accuracy: 0.7850 - loss: 0.6154 - val_accuracy: 0.6402 - val_loss: 1.1679\n",
            "Epoch 8/32\n",
            "1563/1563 - 46s - 29ms/step - accuracy: 0.8013 - loss: 0.5634 - val_accuracy: 0.6450 - val_loss: 1.2029\n",
            "Epoch 9/32\n",
            "1563/1563 - 85s - 54ms/step - accuracy: 0.8185 - loss: 0.5131 - val_accuracy: 0.6272 - val_loss: 1.2907\n",
            "Epoch 10/32\n",
            "1563/1563 - 45s - 29ms/step - accuracy: 0.8331 - loss: 0.4698 - val_accuracy: 0.6279 - val_loss: 1.3686\n",
            "Epoch 11/32\n",
            "1563/1563 - 56s - 36ms/step - accuracy: 0.8453 - loss: 0.4364 - val_accuracy: 0.6273 - val_loss: 1.4401\n",
            "Epoch 12/32\n",
            "1563/1563 - 48s - 31ms/step - accuracy: 0.8592 - loss: 0.3994 - val_accuracy: 0.6275 - val_loss: 1.4793\n",
            "Epoch 13/32\n",
            "1563/1563 - 80s - 51ms/step - accuracy: 0.8654 - loss: 0.3738 - val_accuracy: 0.6251 - val_loss: 1.5755\n",
            "Epoch 14/32\n",
            "1563/1563 - 43s - 27ms/step - accuracy: 0.8755 - loss: 0.3442 - val_accuracy: 0.6235 - val_loss: 1.6740\n",
            "Epoch 15/32\n",
            "1563/1563 - 44s - 28ms/step - accuracy: 0.8832 - loss: 0.3236 - val_accuracy: 0.6218 - val_loss: 1.7972\n",
            "Epoch 16/32\n",
            "1563/1563 - 44s - 28ms/step - accuracy: 0.8947 - loss: 0.2957 - val_accuracy: 0.6227 - val_loss: 1.8605\n",
            "Epoch 17/32\n",
            "1563/1563 - 43s - 27ms/step - accuracy: 0.9000 - loss: 0.2810 - val_accuracy: 0.6257 - val_loss: 2.0132\n",
            "Epoch 18/32\n",
            "1563/1563 - 44s - 28ms/step - accuracy: 0.9045 - loss: 0.2665 - val_accuracy: 0.6198 - val_loss: 2.0337\n",
            "Epoch 19/32\n",
            "1563/1563 - 44s - 28ms/step - accuracy: 0.9105 - loss: 0.2436 - val_accuracy: 0.6118 - val_loss: 2.2449\n",
            "Epoch 20/32\n",
            "1563/1563 - 82s - 52ms/step - accuracy: 0.9135 - loss: 0.2402 - val_accuracy: 0.6197 - val_loss: 2.2623\n",
            "Epoch 21/32\n",
            "1563/1563 - 42s - 27ms/step - accuracy: 0.9194 - loss: 0.2216 - val_accuracy: 0.6145 - val_loss: 2.3479\n",
            "Epoch 22/32\n",
            "1563/1563 - 42s - 27ms/step - accuracy: 0.9237 - loss: 0.2154 - val_accuracy: 0.6192 - val_loss: 2.4579\n",
            "Epoch 23/32\n",
            "1563/1563 - 42s - 27ms/step - accuracy: 0.9291 - loss: 0.1983 - val_accuracy: 0.6134 - val_loss: 2.5125\n",
            "Epoch 24/32\n",
            "1563/1563 - 44s - 28ms/step - accuracy: 0.9290 - loss: 0.1973 - val_accuracy: 0.6074 - val_loss: 2.6934\n",
            "Epoch 25/32\n",
            "1563/1563 - 41s - 27ms/step - accuracy: 0.9307 - loss: 0.1925 - val_accuracy: 0.6088 - val_loss: 2.8013\n",
            "Epoch 26/32\n",
            "1563/1563 - 44s - 28ms/step - accuracy: 0.9341 - loss: 0.1822 - val_accuracy: 0.6079 - val_loss: 2.8928\n",
            "Epoch 27/32\n",
            "1563/1563 - 48s - 30ms/step - accuracy: 0.9349 - loss: 0.1820 - val_accuracy: 0.6064 - val_loss: 3.0617\n",
            "Epoch 28/32\n",
            "1563/1563 - 45s - 29ms/step - accuracy: 0.9407 - loss: 0.1659 - val_accuracy: 0.6081 - val_loss: 3.1135\n",
            "Epoch 29/32\n",
            "1563/1563 - 45s - 29ms/step - accuracy: 0.9395 - loss: 0.1710 - val_accuracy: 0.6081 - val_loss: 3.2452\n",
            "Epoch 30/32\n",
            "1563/1563 - 42s - 27ms/step - accuracy: 0.9421 - loss: 0.1634 - val_accuracy: 0.6058 - val_loss: 3.3384\n",
            "Epoch 31/32\n",
            "1563/1563 - 42s - 27ms/step - accuracy: 0.9427 - loss: 0.1643 - val_accuracy: 0.6165 - val_loss: 3.4738\n",
            "Epoch 32/32\n",
            "1563/1563 - 42s - 27ms/step - accuracy: 0.9457 - loss: 0.1542 - val_accuracy: 0.6066 - val_loss: 3.4943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see here now **after 32 epochs** that the accuracy on the training data is pretty good, it's 95%."
      ],
      "metadata": {
        "id": "FWtocrNwWMzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, if we look at the **validation accuracy**, so that's **the accuracy on the test dataset, we only have a 61% accuracy**. So that's a clear **indication of overfitting**, where we see that **it learns the training dataset, but does less well on the test dataset**."
      ],
      "metadata": {
        "id": "vCmV-O1MWWdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified CNN Version"
      ],
      "metadata": {
        "id": "P4Iw9VWhqnuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're trying to **classify one out of 10 different categories**, and in 61% of the cases we get it right with a simple network but I think we can do better. So let's move on to a network where we have made it a little bit more complex . So in this notebook, we will now have a little bit of a more complex network."
      ],
      "metadata": {
        "id": "FrW7beFKqX98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The initial code is the same as before but now that the network definition is different. We have a one **first convolutional layer here, followed by a dropout layer for regularization, another convolutional layer, and then another dropout**, **another convolution, dropout, convolutions**. We **have four convolutional layers here**. And then after that we **have a max pooling layer**. We have **a dropout again**, and then **we flatten it** and then we do **three fully connected layers**. So we have **four convolutional layers and three fully connected layers**. And we **use relu neurons for all the convolutional and the fully connected layers, except for the last one where we do the soft max activation**."
      ],
      "metadata": {
        "id": "sU2RKCgfrhOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n"
      ],
      "metadata": {
        "id": "-FpqSiDkrSj5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with 4 convolutional and 2 fully-connected layers\n",
        "# using dropout and max-pooling.\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (4, 4), activation='relu', padding='same',\n",
        "                 input_shape=(32, 32, 3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (2, 2), activation='relu', padding='same',\n",
        "                 strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "y6fk91kNrQNK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then the rest of the things are the same as well. We print out the summary of the network and we see here the** number of trainable parameters** for each of the layers."
      ],
      "metadata": {
        "id": "ya3rjLQls_Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics =['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "Z1dWvotHtIb7",
        "outputId": "076134e4-8e3d-4b8a-d83b-5093f2a937a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m3,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m16,448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m131,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m183,242\u001b[0m (715.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">183,242</span> (715.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m183,242\u001b[0m (715.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">183,242</span> (715.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can see here now that we have trained it for 32 epochs, that the **training accuracy is at 75%* and the **validation accuracy is at 75.6%**, so almost 76%.\n",
        "\n",
        "So by having this more,**this deeper network with more layers, we, and adding dropout regularization, not only did we manage to get the over fitting under control, but we also got the validation accuracy** to improve significantly.\n",
        "\n",
        "So now in 76% of the cases, we managed to **predict/or classify the correct image out of this dataset**."
      ],
      "metadata": {
        "id": "GRCxqX4wtTme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_images, train_labels, validation_data =\n",
        "    (test_images, test_labels), epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE, verbose=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOwU5MgdtQv6",
        "outputId": "439edfa2-96ef-4349-ce98-158aaf32517d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "1563/1563 - 221s - 141ms/step - accuracy: 0.3843 - loss: 1.6769 - val_accuracy: 0.5155 - val_loss: 1.3512\n",
            "Epoch 2/32\n",
            "1563/1563 - 268s - 171ms/step - accuracy: 0.5288 - loss: 1.3172 - val_accuracy: 0.6170 - val_loss: 1.1050\n",
            "Epoch 3/32\n",
            "1563/1563 - 273s - 175ms/step - accuracy: 0.5861 - loss: 1.1698 - val_accuracy: 0.6579 - val_loss: 0.9968\n",
            "Epoch 4/32\n",
            "1563/1563 - 222s - 142ms/step - accuracy: 0.6208 - loss: 1.0812 - val_accuracy: 0.6689 - val_loss: 0.9621\n",
            "Epoch 5/32\n",
            "1563/1563 - 225s - 144ms/step - accuracy: 0.6402 - loss: 1.0267 - val_accuracy: 0.6868 - val_loss: 0.9160\n",
            "Epoch 6/32\n",
            "1563/1563 - 223s - 143ms/step - accuracy: 0.6561 - loss: 0.9836 - val_accuracy: 0.6936 - val_loss: 0.8937\n",
            "Epoch 7/32\n",
            "1563/1563 - 220s - 141ms/step - accuracy: 0.6670 - loss: 0.9492 - val_accuracy: 0.6978 - val_loss: 0.8731\n",
            "Epoch 8/32\n",
            "1563/1563 - 267s - 171ms/step - accuracy: 0.6760 - loss: 0.9262 - val_accuracy: 0.6948 - val_loss: 0.8845\n",
            "Epoch 9/32\n",
            "1563/1563 - 217s - 139ms/step - accuracy: 0.6846 - loss: 0.9041 - val_accuracy: 0.7117 - val_loss: 0.8522\n",
            "Epoch 10/32\n",
            "1563/1563 - 260s - 167ms/step - accuracy: 0.6909 - loss: 0.8865 - val_accuracy: 0.7074 - val_loss: 0.8403\n",
            "Epoch 11/32\n",
            "1563/1563 - 221s - 141ms/step - accuracy: 0.6983 - loss: 0.8664 - val_accuracy: 0.7175 - val_loss: 0.8113\n",
            "Epoch 12/32\n",
            "1563/1563 - 225s - 144ms/step - accuracy: 0.7034 - loss: 0.8513 - val_accuracy: 0.7305 - val_loss: 0.7883\n",
            "Epoch 13/32\n",
            "1563/1563 - 225s - 144ms/step - accuracy: 0.7066 - loss: 0.8415 - val_accuracy: 0.7260 - val_loss: 0.8022\n",
            "Epoch 14/32\n",
            "1563/1563 - 218s - 140ms/step - accuracy: 0.7123 - loss: 0.8281 - val_accuracy: 0.7388 - val_loss: 0.7753\n",
            "Epoch 15/32\n",
            "1563/1563 - 223s - 143ms/step - accuracy: 0.7160 - loss: 0.8182 - val_accuracy: 0.7434 - val_loss: 0.7604\n",
            "Epoch 16/32\n",
            "1563/1563 - 223s - 143ms/step - accuracy: 0.7211 - loss: 0.8073 - val_accuracy: 0.7418 - val_loss: 0.7602\n",
            "Epoch 17/32\n",
            "1563/1563 - 223s - 143ms/step - accuracy: 0.7223 - loss: 0.8012 - val_accuracy: 0.7267 - val_loss: 0.7951\n",
            "Epoch 18/32\n",
            "1563/1563 - 256s - 164ms/step - accuracy: 0.7279 - loss: 0.7886 - val_accuracy: 0.7408 - val_loss: 0.7616\n",
            "Epoch 19/32\n",
            "1563/1563 - 222s - 142ms/step - accuracy: 0.7341 - loss: 0.7732 - val_accuracy: 0.7432 - val_loss: 0.7608\n",
            "Epoch 20/32\n",
            "1563/1563 - 221s - 142ms/step - accuracy: 0.7340 - loss: 0.7711 - val_accuracy: 0.7551 - val_loss: 0.7316\n",
            "Epoch 21/32\n",
            "1563/1563 - 226s - 145ms/step - accuracy: 0.7348 - loss: 0.7620 - val_accuracy: 0.7519 - val_loss: 0.7338\n",
            "Epoch 22/32\n",
            "1563/1563 - 224s - 143ms/step - accuracy: 0.7362 - loss: 0.7691 - val_accuracy: 0.7483 - val_loss: 0.7368\n",
            "Epoch 23/32\n",
            "1563/1563 - 254s - 162ms/step - accuracy: 0.7396 - loss: 0.7544 - val_accuracy: 0.7560 - val_loss: 0.7135\n",
            "Epoch 24/32\n",
            "1563/1563 - 213s - 137ms/step - accuracy: 0.7399 - loss: 0.7539 - val_accuracy: 0.7522 - val_loss: 0.7316\n",
            "Epoch 25/32\n",
            "1563/1563 - 220s - 141ms/step - accuracy: 0.7441 - loss: 0.7453 - val_accuracy: 0.7518 - val_loss: 0.7248\n",
            "Epoch 26/32\n",
            "1563/1563 - 274s - 176ms/step - accuracy: 0.7446 - loss: 0.7390 - val_accuracy: 0.7521 - val_loss: 0.7279\n",
            "Epoch 27/32\n",
            "1563/1563 - 246s - 158ms/step - accuracy: 0.7479 - loss: 0.7400 - val_accuracy: 0.7463 - val_loss: 0.7384\n",
            "Epoch 28/32\n",
            "1563/1563 - 268s - 171ms/step - accuracy: 0.7510 - loss: 0.7314 - val_accuracy: 0.7570 - val_loss: 0.7193\n",
            "Epoch 29/32\n",
            "1563/1563 - 221s - 142ms/step - accuracy: 0.7486 - loss: 0.7313 - val_accuracy: 0.7543 - val_loss: 0.7205\n",
            "Epoch 30/32\n",
            "1563/1563 - 225s - 144ms/step - accuracy: 0.7525 - loss: 0.7201 - val_accuracy: 0.7599 - val_loss: 0.7055\n",
            "Epoch 31/32\n",
            "1563/1563 - 256s - 164ms/step - accuracy: 0.7533 - loss: 0.7195 - val_accuracy: 0.7624 - val_loss: 0.7050\n",
            "Epoch 32/32\n",
            "1563/1563 - 269s - 172ms/step - accuracy: 0.7527 - loss: 0.7159 - val_accuracy: 0.7624 - val_loss: 0.7071\n"
          ]
        }
      ]
    }
  ]
}